There's a possibility that this single package may drastically
grow beyond its initial purpose, or at the very least, that it'll be the
gateway for client servers to ask for lower-level operations over the
network (i.e. redo logging, undo segmentations, caching, shared pools for multiple database endpoints, autoscaling pool size for varying resource usage,
and the all-to-important logging.

In the event that this does become the case, this preamble marks my awareness
that I may have bargained for more than I initially set out to do.
Who knows? Maybe this will even become a side-gig? Hopefully the core team
won't discover how incompetent and unprepared I really am. :)

In any case, if you're reading this and you're mildly intrigued, feel free to
tag along! The more, the merrier!

=============================================================================
Wed 22:18 5-6-2020 (haha, like I'll really continue this labeling trend)
Today's agenda is configurations, online studies of other architectures, and
figuring out how to make thing's as simple as possible for me and my users.

Meta goals:
1) Pen-and-paper out some basic designs and move them to images
2) Scavenge pieces from my async LDAP project
3) Review that interesting video on EdgeDB's spectrum chat with the master node
    election. I think it'll be important to consider those concepts for future
    load-balancing scenarios.

==============================================================================
Thurs (technically Friday) Fi 01:24 5-8-2020
Last-last night I worked out a topology for EdgeDBus, the framework that I'm
building this whole thing for in the first place. It will be an internet-exposed
service comprised of the "internet frontier" which includes two layers of 
security policies and procedures, an executive broadcaster linked to a message
brokering relay, and a community of maangers and workers -- as defined by the
properties read from an initial configuration script. Arguably the most exciting
part about this service is how it can be deployed. Because it will use the lazyscript
tool I invented, deployment will be able to cater to those tricky
~software as a service~ models that AWS, Azure, and Digital Ocean are all so hyped
up about.

Today's work, however, does not reflect those lofty goals. Instead, I created a 
not-so-simple RPC reverse shell server to accomodate the software
testing environment that edbpool requires.

Once the docker container is built on the developer's machine, and all of the
configuration steps are completed, it's routinely easy to automate testing
without having to destroy and rebuild the entire docker image and database.

This should make sense since my role in this is not actually to test and debug
the database instance itself, but rather to create an abstraction over the
python API because (in my humble opinion) it's still too hard to use the best-performing
interface even though the core team has clearly gone to great lengths to make it simpler.
To be clear, this abstraction is necessary because connection pools behave
fundamentally differently from a 


Because the purpose of a connection pool is to greatly enhance performance connectivity
by reducing the lag of slow I
